---
title: "QM 2021 Week 11: Count Models"
author:
  - "Oliver Rittmann"
  - "Viktoriia Semenova"
  - "David Grundmanns"
date: "November 25 | 29 | 30, 2021"
output:
  html_document:
    toc: yes
    number_sections: yes
    toc_float: yes
    highlight: tango
    css: css/lab.css
    self_contained: yes
  pdf_document:
    toc: yes
bibliography: citations.bib # this adds a bibliography file from the repo
biblio-style: apsr # this selects the style 
editor_options: 
  chunk_output_type: inline
  markdown: 
    wrap: sentence
---

------------------------------------------------------------------------

## Today we will learn: {.unnumbered }

1.   MLE: Poisson Regression
2.   Poisson and Negative Binomial in GLM
3.   Likelihood Ratio Test (Overdispersion)
4.   Expected Values


In other words, the goals are to:

-   Implement MLE for count models
-   Use count models with GLM
-   Compute meaningful quantities of interest

---

```{r setup, message=FALSE, warning=FALSE, results='hide'}
# The first line sets an option for the final document that can be produced from
# the .Rmd file. Don't worry about it.
knitr::opts_chunk$set(echo = TRUE,
                      collapse = TRUE,
                      out.width="\\textwidth", # for larger figures 
                      attr.output = 'style="max-height: 200px"',
                      tidy = 'styler' # styles the code in the output 
                      )

# The next bit is quite powerful and useful. 
# First you define which packages you need for your analysis and assign it to 
# the p_needed object. 
p_needed <-
  c("ggplot2", "viridis", "MASS", "optimx", "scales", "foreign", 
    "separationplot", "patchwork", "stargazer", "ggplotify")

# Now you check which packages are already installed on your computer.
# The function installed.packages() returns a vector with all the installed 
# packages.
packages <- rownames(installed.packages())
# Then you check which of the packages you need are not installed on your 
# computer yet. Essentially you compare the vector p_needed with the vector
# packages. The result of this comparison is assigned to p_to_install.
p_to_install <- p_needed[!(p_needed %in% packages)]
# If at least one element is in p_to_install you then install those missing
# packages.
if (length(p_to_install) > 0) {
  install.packages(p_to_install)
}
# Now that all packages are installed on the computer, you can load them for
# this project. Additionally the expression returns whether the packages were
# successfully loaded.
sapply(p_needed, require, character.only = TRUE)

# This is an option for stargazer tables
# It automatically adapts the output to html or latex,
# depending on whether we want a html or pdf file
stargazer_opt <- ifelse(knitr::is_latex_output(), "latex", "html")


# only relevant for ggplot2 plotting
# setting a global ggplot theme for the entire document to avoid 
# setting this individually for each plot 
theme_set(theme_classic() + # start with classic theme 
  theme(
    plot.background = element_blank(),# remove all background 
    plot.title.position = "plot", # move the plot title start slightly 
    legend.position = "bottom" # by default, put legend on the bottom
  ))

```


# MLE: Poisson Regression

What first? We start with some fake data...

We need a population (here 100000 observations)

```{r}
n <- 100000

# We set true parameters for \beta_0 and \beta_1

beta0 <- 1
beta1 <- 0.5

# and generate an independent variable X

X <- rnorm(n, 0, 1)
```

Now we can generate lambda via the exponential response function

```{r}
exp_resp <- function(beta0, beta1, X){
  lambda <- exp(beta0 + beta1*X)
  return(lambda)
}

lambda <- exp_resp(beta0 = beta0, 
                   beta1 = beta1, 
                   X = X)
```

Finally, we can get Y from the underlying poisson distribution
Remember `r`, `d`, `q`, `p`?

```{r}
Y <- rpois(n, lambda)

summary(Y)
hist(Y)
```

## Exercise I: Poisson MLE

The Poisson PDF for a single observation:

$$
f_{Poisson}(y_{i}|\lambda) = 
\begin{cases}
  \frac{e^{-\lambda}\lambda^{y_{i}}}{y_{i}!} & 
    \text{ for } \lambda > 0\text{ and }y_{i}=0,1,\ldots\\
  0 & 
    otherwise
\end{cases}
$$

The probability density of all the data (i.e., $N$ observations, given that $Y_i$ and $Y_j$ are independent conditional on $X$ for all $i\not= j$ and identically distributed)  is the product of all $N$ individual observations:

$$
Pr(Y|\lambda) = \prod_{i=1}^{N}	\frac{e^{-\lambda}\lambda^{y_{i}}}{y_{i}!} 
$$

This is the likelihood. But as usual, we prefer the log-likelihood:

$$
\ln L(\lambda|Y) = \sum_{i=1}^{n} (y_{i} ln(\lambda_i) - \lambda_i)
$$

Replacing $\lambda$ with the linear component (i.e. $X_{i}\beta$) gives us the likelihood function of our model:

$$
\ln L(\beta|Y) = \sum_{i=1}^{n} (y_{i} (X_{i}\beta) -e^{X_{i}\beta})\\
$$

1) Program the Poisson log-likelihood function (slide 13 will help you)
2) Find the MLE using optimx (or optim)

```{r}
## Poisson MLE

# Log Likelihood
pois_ll <- function(X, Y, theta) {
  beta0 <- theta[1]
  beta1 <- theta[2]
  
  logl <- sum(Y * (beta0 + beta1 * X) - exp(beta0 + beta1 * X))
  return(logl)
}
```


```{r}
# Optim
# Starting Values
stval <- c(0, 0)

library(optimx)
res <-
  optimx(
    stval,
    pois_ll ,
    Y = Y,
    X = X,
    control = list(maximize = T)
  )
res

# res <- optim(stval,pois.ll,Y=Y,X=X, control = list(fnscale = -1))
# res
```

(How) Can we interpret those coefficients? 

## Exercise II: Eck and Hultman 2007: One-sided violence against civilians 

a) Load the eck_rep.dta dataset
b) Estimate the effect of autocracy on one-sided violence

```{r}
dta <- read.dta("raw-data/eck_rep.dta", convert.factors = FALSE)

#  Some data preparation

dta$os_best[dta$os_best == 500000] <- NA # Rwanda


# Omit NAs (as our log-likelihood can't handle missings)

dta2 <- na.omit(dta[,c("os_best", "auto")])

# Maximize log-likelihood function

res2 <-
  optimx(
    stval,
    pois_ll,
    Y = dta2$os_best,
    X = dta2$auto,
    control = list(maximize = T)
  )
res2

# res2 <- optim(stval, pois.ll, Y = dta2$os_best, X = dta2$auto, control = list(fnscale = -1))
# res2
```

Find out how well you did. Compare it with the built-in GLM Poisson:

```{r}
m1 <- glm(os_best ~ auto, dta2, family = "poisson")

coef(m1)

# Compare to our likelihood function

res2
```

# Poisson and Negative Binomial in GLM

We are going to replicate model 4, p.243 in @eck_hultman_2007.


```{r}
# We start with a Poisson Model

m1 <- glm(
  os_best ~ intensity_dyad + auto + demo + govt + prior_os,
  data = dta,
  family = "poisson"
)

summary(m1)

# Negative Binomial Model

m2 <-
  glm.nb(
    os_best ~ intensity_dyad + auto + demo + govt + prior_os,
    data = dta,
    control = glm.control(maxit = 100)
  )

summary(m2)

# control=glm.control(maxit=100) increases the
# number of maximum interations
```


Make a nice looking latex table of both models.

```{r, results='asis'}
stargazer(
  list(m1, m2),
  out = "table_lab.tex",
  title = "Regression Results",
  notes = "Excluding observation  Rwanda 1994",
  intercept.bottom = TRUE,
  covariate.labels = c(
    "Civil War",
    "Autocracy",
    "Democracy",
    "Government",
    "One sided Violence t-1",
    "Constant"
  ),
  type = stargazer_opt
)
```

# Likelihood Ratio Test (Overdispersion)

The likelihood ratio test is a test to compare two models, one of which is a special case of the other (Restricted and Unrestricted Model...).

Let L1 be the likelihood for the null model with m parameters and L2 be the likelihood for the alternative model with n parameters, n > m. One can show that when $n \to \infty$, $-2 \times log(\frac{L1}{L2})$ converges  to the $\chi^2$ distribution with $k = n - m$ degrees of freedom. See also DeGroot and Schervish (2012), Probability and Statistics, pp. 544/545

Thus, $LRT = -2*log(L1) + 2*log(L2)$

```{r}
L1 <- logLik(m1) # Log Likelihood of model 1
L2 <- logLik(m2) # Log Likelihood of model 2

LRT <- -2 * L1 + 2 * L2 # converges to chi^2 distribution

# Reject H0 if ... What is our H0 here?

LRT > qchisq(0.95, df = 1)
```


# Quantities of Interest

As usually we can interpret the results better if we look at meaningful quantities of interest.

We look at the model from the Eck/Hultman paper.

```{r}
m2 <-
  glm.nb(
    os_best ~ intensity_dyad + auto + demo + govt + prior_os,
    data = dta,
    control = glm.control(maxit = 100)
  )
```


## A. Simulate Parameters - Remember the Steps? {.unnumbered}

Steps for Simulating Parameters (Estimation Uncertainty)
1. Get the coefficients from the regression (gamma.hat)
2. Get the variance-covariance matrix (V.hat)
3. Set up a multivariate normal distribution N(gamma.hat,V.hat)
4. Draw from the distribution nsim times


```{r}
nsim <- 1000

gamma_hat <- coef(m2)

V_hat <- vcov(m2)

S <- mvrnorm(nsim, gamma_hat, V_hat)
```


## B. Calculate Expected Values {.tabset .unnumbered}

Set up interesting scenarios.

Autocracies

```{r}
scenario1 <-
  cbind(
    1,
    median(dta$intensity_dyad, na.rm = TRUE),
    1,
    0,
    median(dta$govt, na.rm = TRUE),
    mean(dta$prior_os, na.rm = TRUE)
  ) 
```


Democracies

```{r}
scenario2 <- cbind(
  1,
  median(dta$intensity_dyad, na.rm = TRUE),
  0,
  1,
  median(dta$govt, na.rm = TRUE),
  mean(dta$prior_os, na.rm = TRUE)
)
```


Anocracies

```{r}
scenario3 <- cbind(
  1,
  median(dta$intensity_dyad, na.rm = TRUE),
  0,
  0,
  median(dta$govt, na.rm = TRUE),
  mean(dta$prior_os, na.rm = TRUE)
) 
```


```{r}
Xbeta1 <- S %*% t(scenario1)

Xbeta2 <- S %*% t(scenario2)

Xbeta3 <- S %*% t(scenario3)
```


To get expected values for lambda, we need to plug in the Xbeta values into the response function 

```{r}
lambda1 <- exp(Xbeta1)

lambda2 <- exp(Xbeta2)

lambda3 <- exp(Xbeta3)
```

Now we need an additional step: Plug the lambda and theta into the negative binomial distribution. And then we average over the fundamental uncertainty for expected values. Please have a look at the King et al. 2001 article from Week 7 again for further information. 

Get the theta.

```{r}
theta <- m2$theta

exp_auto <-
  sapply(lambda1, function(x)
    mean(rnbinom(1000, size = theta, mu = x)))

exp_demo <-
  sapply(lambda2, function(x)
    mean(rnbinom(1000, size = theta, mu = x)))

exp_ano <-
  sapply(lambda3, function(x)
    mean(rnbinom(1000, size = theta, mu = x)))

#we could have also done this in a for-loop

# mean.auto <- rep(NA, length(lambda1))
#
# for(i in 1:length(lambda1)){
#
# mean.auto[i] <- mean(rnbinom(1000, size = theta, mu = lambda1[i]))
#
# }
```


Now we want to plot it. 

### Base R {.unnumbered}

```{r}
d1 <- density(exp_auto)
d2 <- density(exp_demo)
d3 <- density(exp_ano)

plot(d3, 
     main = "Expected Killings in Democracies, Autocracies and Anocracies",
     xlab = "Expected killings by rebel groups in civil war situation 
     with 48 killings in the prior year (mean value)",
     yaxt = "n", ylab = "",
     xlim = c(0, 60),
     type = "n",
     bty = "n")
polygon(d3, col="#ff000050", border="black") # red: Anocracy
polygon(d2, col="#0000ff50", border="black") # blue: Democracy
polygon(d1, col="#00ff5550", border="black") # green: Autocracy
legend("topright",
       c("Anocracy", "Democracy", "Autocracy"),
       fill= c("#ff000050", "#0000ff50", "#00ff5550"),
       col = c("black", "green", "red"), bty = "n")

```

### ggplot2 {.unnumbered}

We want to make an Expected Values Plot

```{r}
exp_values <- c(exp_auto, exp_demo, exp_ano)
df <- data.frame(exp_values)

df$id <-
  c(rep("Autocracy", 1000),
    rep("Democracy", 1000),
    rep("Anocracy", 1000))
```


```{r}
#pdf("ExpectedValues.pdf") # Uncomment to export the plot as PDF
ggplot(df, aes(x = exp_values, fill = id)) +
  geom_density(alpha = 0.4) +
  guides(fill = guide_legend(title = "")) +
  xlab("Expected Killings") +
  ylab("Density") +
  theme_bw()
#dev.off()
```


# First Differences

In their paper Eck and Hultman also want to look at differences between killings by governments and rebels. We will run similar models and calculate first differences to look at the substantive effects.

Eck and Hultman subset the data to government and rebel killings and run the previous model separately on these two subsets. *Any other ideas how we could incorporate this into one model?*

```{r}
m3 <-
  glm.nb(
    os_best ~ intensity_dyad + auto + demo + prior_os,
    data = dta[dta$govt == 1,],
    control = glm.control(maxit = 100)
  )

m4 <-
  glm.nb(
    os_best ~ intensity_dyad + auto + demo + prior_os,
    data = dta[dta$govt == 0,],
    control = glm.control(maxit = 100)
  )
```

Let's go through the simulation steps again.

```{r}
# Steps for Simulating Parameters (Estimation Uncertainty)
# 1. Get the coefficients from the regression (gamma.hat)
# 2. Get the variance-covariance matrix (V.hat)
# 3. Set up a multivariate normal distribution N(gamma.hat,V.hat)
# 4. Draw from the distribution nsim times

nsim <- 1000

gamma_hat_m3 <- coef(m3)

V_hat_m3 <- vcov(m3)

S_m3 <- mvrnorm(nsim, gamma_hat_m3, V_hat_m3)

# Set up interesting scenarios.

# (Intercept)
# intensity_dyad
# auto
# demo
# prior_os

scenario1 <-
  cbind(1, 1, 1, 0, mean(dta$prior_os, na.rm = T)) # Autocracy
scenario2 <-
  cbind(1, 1, 0, 1, mean(dta$prior_os, na.rm = T)) # Democracy
scenario3 <-
  cbind(1, 1, 0, 0, mean(dta$prior_os, na.rm = T)) # Anocracy


Xbeta1_m3 <- S_m3 %*% t(scenario1)
Xbeta2_m3 <- S_m3 %*% t(scenario2)
Xbeta3_m3 <- S_m3 %*% t(scenario3)

# To get expected values for lambda, we need to plug in the Xbeta values into the response function

lambda1_m3 <- exp(Xbeta1_m3)
lambda2_m3 <- exp(Xbeta2_m3)
lambda3_m3 <- exp(Xbeta3_m3)


# Now we need an additional step: Plug the lambda and theta into the negative binomial distribution.
# And then we average over the fundamental uncertainty for expected values.

theta_m3 <- m3$theta

exp_scenario1_m3 <-
  sapply(lambda1_m3, function(x)
    mean(rnbinom(1000, size = theta_m3, mu = x)))
exp_scenario2_m3 <-
  sapply(lambda2_m3, function(x)
    mean(rnbinom(1000, size = theta_m3, mu = x)))
exp_scenario3_m3 <-
  sapply(lambda3_m3, function(x)
    mean(rnbinom(1000, size = theta_m3, mu = x)))

exp_values_m3 <-
  c(exp_scenario1_m3, exp_scenario2_m3, exp_scenario3_m3)
df_m3 <- data.frame(exp_values_m3)
```

We need to do the same thing for model 4.

```{r}
# Steps for Simulating Parameters (Estimation Uncertainty)
# 1. Get the coefficients from the regression (gamma.hat)
# 2. Get the variance-covariance matrix (V.hat)
# 3. Set up a multivariate normal distribution N(gamma.hat,V.hat)
# 4. Draw from the distribution nsim times

nsim <- 1000

gamma_hat_m4 <- coef(m4)

V_hat_m4 <- vcov(m4)

S_m4 <- mvrnorm(nsim, gamma_hat_m4, V_hat_m4)

# Set up interesting scenarios.

# (Intercept)
# intensity_dyad
# auto
# demo
# prior_os

scenario1 <-
  cbind(1, 1, 1, 0, mean(dta$prior_os, na.rm = T)) # Autocracy
scenario2 <-
  cbind(1, 1, 0, 1, mean(dta$prior_os, na.rm = T)) # Democracy
scenario3 <-
  cbind(1, 1, 0, 0, mean(dta$prior_os, na.rm = T)) # Anocracy


Xbeta1_m4 <- S_m4 %*% t(scenario1)
Xbeta2_m4 <- S_m4 %*% t(scenario2)
Xbeta3_m4 <- S_m4 %*% t(scenario3)

# To get expected values for lambda, we need to plug in the Xbeta values into the response function

lambda1_m4 <- exp(Xbeta1_m4)
lambda2_m4 <- exp(Xbeta2_m4)
lambda3_m4 <- exp(Xbeta3_m4)


# Now we need an additional step: Plug the lambda and theta into the negative binomial distribution.
# And then we average over the fundamental uncertainty for expected values.

theta_m4 <- m4$theta

exp_scenario1_m4 <-
  sapply(lambda1_m4, function(x)
    mean(rnbinom(1000, size = theta_m4, mu = x)))
exp_scenario2_m4 <-
  sapply(lambda2_m4, function(x)
    mean(rnbinom(1000, size = theta_m4, mu = x)))
exp_scenario3_m4 <-
  sapply(lambda3_m4, function(x)
    mean(rnbinom(1000, size = theta_m4, mu = x)))

exp_values_m4 <-
  c(exp_scenario1_m4, exp_scenario2_m4, exp_scenario3_m4)
df_m4 <- data.frame(exp_values_m4)
```

Now we have everything to calculate the first differences:

```{r}
# Model 3: Killings by Rebel Groups
df_m3$fd_auto_dem <- exp_scenario1_m3 - exp_scenario2_m3 # Autocracy - Democracy
df_m3$fd_auto_ano <- exp_scenario1_m3 - exp_scenario3_m3 # Autocracy - Anocracy

# Model 4: Killings by Rebel Groups
df_m4$fd_auto_dem <- exp_scenario1_m4 - exp_scenario2_m4 # Autocracy - Democracy
df_m4$fd_auto_ano <- exp_scenario1_m4 - exp_scenario3_m4 # Autocracy - Anocracy
```

Summarize the result with the Median & CI of First Differences

```{r}
# Autocracy - Democracy M3 (by Government)
median_fd_auto_dem_m3 <- median(df_m3$fd_auto_dem)
ci_fd_auto_dem_m3 <- quantile(df_m3$fd_auto_dem, probs = c(0.025, 0.975))

# Autocracy - Anocracy M3 (by Government)
median_fd_auto_ano_m3 <- median(df_m3$fd_auto_ano)
ci_fd_auto_ano_m3 <- quantile(df_m3$fd_auto_ano, probs = c(0.025, 0.975))

# Autocracy - Democracy M6 (by Rebel Groups)
# dfm6$fd_auto_dem
median_fd_auto_dem_m4<- median(df_m4$fd_auto_dem)
ci_fd_auto_dem_m4 <- quantile(df_m4$fd_auto_dem, probs = c(0.025, 0.975))

# Autocracy - Democracy M6 (by Rebel Groups)
median_fd_auto_ano_m4 <- median(df_m4$fd_auto_ano)
ci_fd_auto_ano_m4 <- quantile(df_m4$fd_auto_ano, probs = c(0.025, 0.975))
```

### Plot first differences {.tabset}

#### base R {.unnumbered}

```{r}
cis <- rbind(ci_fd_auto_dem_m3,
             ci_fd_auto_ano_m3,
             ci_fd_auto_dem_m4,
             ci_fd_auto_ano_m4)

col <- c("black", "black", "grey55", "grey55")

#pdf("Eck-Hultmann_First_Differences.pdf",
#    width = 8,
#    height = 8)
par(mar = c(5, 1, 4, 7) + .1)
plot(
  y = c(4:1),
  x = c(
    median_fd_auto_dem_m3,
    median_fd_auto_ano_m3,
    median_fd_auto_dem_m4,
    median_fd_auto_ano_m4
  ),
  cex = 1.5,
  xlab = 'First Difference and 95%-CI of Expected Killings
     in civil war situation with 48 killings in the prior year (mean)',
  col = col,
  ylab = '',
  yaxt = "n",
  xlim = c(-60, 100),
  ylim = c(0.5 , 4.5),
  pch = 19,
  main = 'First Differences of Expected Killings
Baseline: Autocracy',
bty = "n"
)
axis(
  4,
  at = c(4:1),
  labels = c("Democracy", "Anocracy", "Democracy", "Anocracy"),
  las = 2
)
segments(
  x0 = c(cis[1:4, 1]),
  y0 = c(4:1),
  x1 = c(cis[1:4, 2]),
  y1 = c(4:1),
  col = c(col[1:4]),
  lwd = 2.3
)
segments(
  x0 = 0,
  y0 = 0,
  x1 = 0,
  y1 = 5,
  lty = "dashed"
)
legend(
  "topleft",
  c("by Government", "by Rebel Groups"),
  lty = 1,
  pch = 19,
  lwd = 2,
  col = c(col[1], col[3]),
  bty = "n"
)
```

#### ggplot2 {.unnumbered}

```{r}
#tbd.
```


# Concluding Remarks {.unnumbered .unlisted}

In your final homework you will further explore count models.
